{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "914fda58",
   "metadata": {},
   "source": [
    "### Search Engine With tools and Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8eccee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arxiv -- Research\n",
    "## tools creation\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf2ba75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used the inbuilt tool of wikipedia\n",
    "api_wrapper_wiki=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c9347f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_wrapper_arxiv=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "arxiv=ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4136872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5c17e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## Custom tools[RAG tool]\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d2d7ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000014CD2F66CF0>, search_kwargs={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://docs.langchain.com/langsmith/home\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "# Using a lighter model for faster processing\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\",  \n",
    "    model_kwargs={'device': 'cpu'}\n",
    ")\n",
    "\n",
    "vectordb=FAISS.from_documents(documents, embeddings)\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1d15bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def langsmith_search(query: str) -> str:\n",
    "    \"\"\"Search for information about LangSmith.\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "retriever_tool = langsmith_search\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7336ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[wiki,arxiv,retriever_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8591e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'e:\\\\Gen-ai-projects\\\\genvenv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=250)),\n",
       " StructuredTool(name='langsmith_search', description='Search for information about LangSmith.', args_schema=<class 'langchain_core.utils.pydantic.langsmith_search'>, func=<function langsmith_search at 0x0000014CD3136980>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03d4c0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run all these tools with agents and llm models\n",
    "## tools,llm-->agentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import SecretStr\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\",\"\")\n",
    "openai_api_key = os.getenv(\"OPENROUTER_API_KEY\",\"\")\n",
    "\n",
    "llm1 = ChatOpenAI(\n",
    "    model=\"tngtech/tng-r1t-chimera:free\",\n",
    "    api_key=SecretStr(openai_api_key),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.7\n",
    ")\n",
    "llm2=ChatGroq(\n",
    "    api_key=SecretStr(groq_api_key),\n",
    "    model=\"qwen/qwen3-32b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d240d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prompt template - using ChatPromptTemplate instead of hub\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use the provided tools to answer questions.\"),\n",
    "    MessagesPlaceholder(\"chat_history\", optional=True),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6d264c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayang\\AppData\\Local\\Temp\\ipykernel_7852\\1608783035.py:4: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent_executor = create_react_agent(llm2, tools)\n"
     ]
    }
   ],
   "source": [
    "## Create agent using LangGraph's create_react_agent\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "agent_executor = create_react_agent(llm2, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d208b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith is a comprehensive platform for developing, debugging, and deploying **Large Language Model (LLM) applications**. Here's a concise overview:\n",
      "\n",
      "### Key Features:\n",
      "1. **Framework-Agnostic**: Works with or without LangChainâ€™s open-source libraries (`langchain` and `langgraph`).\n",
      "2. **Integrated Workflow**:\n",
      "   - **Observability**: Trace requests and debug applications.\n",
      "   - **Evaluation**: Measure and track AI output quality over time.\n",
      "   - **Deployment**: Manage deployments and scale agents in production.\n",
      "3. **Development Tools**:\n",
      "   - **Agent Builder (Beta)**: No-code interface for designing and deploying AI agents.\n",
      "   - **Studio**: Visual interface for building, testing, and refining LLM applications end-to-end.\n",
      "   - **Prompt Engineering**: Test and iterate on prompts with versioning and collaboration.\n",
      "\n",
      "4. **Security & Compliance**:\n",
      "   - Meets **HIPAA, SOC 2 Type 2, and GDPR** standards.\n",
      "   - Secure data management and access control.\n",
      "\n",
      "5. **Flexibility**:\n",
      "   - Deploy in **managed cloud, self-hosted, or hybrid** environments.\n",
      "   - Supports local prototyping to production workflows.\n",
      "\n",
      "### Getting Started:\n",
      "- **Account**: Sign up at [smith.langchain.com](https://smith.langchain.com) (no credit card required).\n",
      "- **API Key**: Generated via the Settings page for authentication.\n",
      "- **Quickstarts**: Choose from observability, evaluation, or deployment workflows.\n",
      "\n",
      "### Recent Updates:\n",
      "- **LangGraph Platform** is now **LangSmith Deployment** (see changelog for details).\n",
      "\n",
      "LangSmith is ideal for teams seeking to streamline LLM development while ensuring reliability, security, and scalability. ðŸš€\n"
     ]
    }
   ],
   "source": [
    "## Test the agent\n",
    "result = agent_executor.invoke({\"messages\": [(\"user\", \"Tell me about LangSmith\")]})\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be360831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a recent paper about transformers in AI from arXiv:\n",
      "\n",
      "**Title:** Foundations of GenIR  \n",
      "**Authors:** Qingyao Ai, Jingtao Zhan, Yiqun Liu  \n",
      "**Published:** 2025-01-06  \n",
      "\n",
      "**Summary:**  \n",
      "This paper explores how modern generative AI models (like transformers) are transforming information access systems. It contrasts traditional AI approaches with the new paradigm of generative models, addressing challenges in knowledge distillation, retrieval-augmented generation, and the integration of large language models into retrieval systems.\n",
      "\n",
      "Would you like me to expand on any specific aspects of this paper?\n"
     ]
    }
   ],
   "source": [
    "## Test with Arxiv\n",
    "result = agent_executor.invoke({\"messages\": [(\"user\", \"Find recent papers about transformers in AI\")]})\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1f223c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) is a field of study within artificial intelligence (AI) focused on developing algorithms that enable computers to learn patterns and make decisions from data. These algorithms improve their performance on tasks over time without being explicitly programmed for specific outcomes. Key aspects include:\n",
      "\n",
      "1. **Learning from Data**: ML models identify patterns in historical or input data to make predictions or decisions.\n",
      "2. **Generalization**: They adapt to new, unseen data by applying learned patterns rather than following rigid rules.\n",
      "3. **Statistical Foundations**: Most methods rely on statistical techniques to optimize performance and minimize errors.\n",
      "4. **Applications**: Used in diverse fields like image recognition, natural language processing, finance, healthcare, and more.\n",
      "\n",
      "For example, a machine learning model trained on thousands of cat and dog photos can later classify new images as \"cat\" or \"dog\" with high accuracy. The field continues to evolve with advancements in deep learning, reinforcement learning, and other sub-disciplines.\n"
     ]
    }
   ],
   "source": [
    "## Test with Wikipedia\n",
    "result = agent_executor.invoke({\"messages\": [(\"user\", \"What is machine learning?\")]})\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0089ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
